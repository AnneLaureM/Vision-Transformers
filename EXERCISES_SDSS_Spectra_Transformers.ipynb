{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# EXERCISES \u2014 SDSS Spectra Classification with Transformer Encoders (Binary & Multiclass)\nGenerated on 2025-10-28T18:01:56.090282Z\n\n> Exercises-only notebook. Read the guidance, then complete the TODO blocks. No solutions are included."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n## Objective\n\nYou will:\n- Acquire a tiny working set of SDSS spectra using **astroquery** and the **Nair & Abraham (2010)** catalog (Vizier).\n- Prepare train/val/test arrays for **binary** and **multiclass** classification.\n- Build a **Transformer Encoder** model for spectra.\n- Train, evaluate, and analyze results (ROC, PR, confusion matrix, macro-F1, calibration hints).\n\nThis notebook is *exercises-only*: there are **no solutions**. Follow the guidance and fill the TODOs.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 0. Environment Notes\n\n- Internet may be required for the Vizier/SDSS steps. If not available, skip the download cells and place your prepared files under `./spectra` and `./catalog` before continuing.\n- Recommended packages: `astroquery`, `astropy`, `numpy`, `pandas`, `torch`, `matplotlib`, `scikit-learn`.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# 0. Create directories if not exist\nimport os\nos.makedirs('spectra', exist_ok=True)\nos.makedirs('images', exist_ok=True)       # not used in this notebook, but kept for symmetry\nos.makedirs('catalog', exist_ok=True)\nos.makedirs('intermediate', exist_ok=True)\nprint(\"Directories ready.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 1. Download Nair & Abraham (2010) catalog (Vizier)\n\nIf `astroquery` is not installed, uncomment the pip line below.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# Install astroquery if needed (uncomment in your environment)\n# !pip install astroquery\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom astroquery.vizier import Vizier\nimport pandas as pd\nimport os\n\n# Set Vizier row limit to maximum\nVizier.ROW_LIMIT = -1\n\n# Query the Nair & Abraham (2010) catalog\ncatalog_id = 'J/ApJS/186/427'\nvizier = Vizier(columns=['*'])\nresult = vizier.get_catalogs(catalog_id)\n\n# Convert to pandas DataFrame\ncatalog_df = result[0].to_pandas()\n\n# Save to CSV for later use\nos.makedirs('./catalog', exist_ok=True)\ncatalog_df.to_csv('./catalog/nair_abraham_2010.csv', index=False)\n\nprint(f\"Downloaded {len(catalog_df)} galaxies from Nair & Abraham (2010) catalog\")\nprint(f\"Available columns: {list(catalog_df.columns)[:12]} ...\")\ncatalog_df.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 2. Query SDSS for spectra (tiny sample)\n\nWe cone-search around RA/Dec for a handful of sources and download the corresponding FITS spectra.\n\nIf you already have spectra, skip this and ensure FITS files live under `./spectra/`.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# Install astroquery if needed (uncomment in your environment)\n# !pip install astroquery\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom astroquery.sdss import SDSS\nfrom astropy.io import fits\nimport pandas as pd\nimport os\nfrom astropy import coordinates as coords\nfrom astropy import units as u\n\n# Directory to save spectra\nos.makedirs('./spectra', exist_ok=True)\n\n# Example: Search for spectra for the first 10 sources using RA/Dec cone search\n# Use the correct column names from Nair & Abraham catalog: '_RA' and '_DE'\nrows = catalog_df.dropna(subset=['_RA', '_DE']).head(10)\n\nprint(f\"Searching for SDSS spectra for {len(rows)} galaxies...\")\n\nspec_matches = []\nfor idx, row in rows.iterrows():\n    ra = row['_RA']\n    dec = row['_DE']\n    sdss_name = row.get('SDSS', f'nair_{idx}')  # SDSS identifier if present\n    \n    source_id = f\"nair_{idx}\"\n    try:\n        pos = coords.SkyCoord(ra, dec, unit='deg')\n        # Query for spectroscopic objects within 3 arcsec\n        spec_query = SDSS.query_region(pos, radius=3*u.arcsec, spectro=True)\n        \n        if spec_query is not None and len(spec_query) > 0:\n            # Pick the closest match\n            match = spec_query[0]\n            plate = match['plate']\n            fiberID = match['fiberID']\n            mjd = match['mjd']\n            specobjid = match['specobjid']\n            \n            fits_path = f'./spectra/spec-{specobjid}.fits'\n            \n            # Skip if already on disk\n            if os.path.exists(fits_path):\n                print(f\"Spectrum exists, skipping: {fits_path}\")\n            else:\n                sp = SDSS.get_spectra(plate=plate, fiberID=fiberID, mjd=mjd)\n                if sp:\n                    sp[0].writeto(fits_path, overwrite=True)\n                    print(f\"Downloaded: {fits_path} for {sdss_name} at RA={ra:.6f}, Dec={dec:.6f}\")\n                else:\n                    print(f\"Failed to download spectrum for {sdss_name}\")\n                    continue\n            \n            spec_matches.append({\n                'source_id': source_id,\n                'sdss_name': sdss_name,\n                'ra': ra, 'dec': dec,\n                'specobjid': specobjid,\n                'spectrum_file': fits_path,\n                'plate': plate, 'fiber': fiberID, 'mjd': mjd\n            })\n        else:\n            print(f\"No spectrum found near {sdss_name} at RA={ra:.6f}, Dec={dec:.6f}\")\n    except Exception as e:\n        print(f\"Error for {sdss_name} at RA={ra:.6f}, Dec={dec:.6f}: {e}\")\n\n# Save spectroscopic matches\nif spec_matches:\n    spec_df = pd.DataFrame(spec_matches)\n    os.makedirs('./intermediate', exist_ok=True)\n    spec_df.to_csv('./intermediate/sdss_spectra_matches.csv', index=False)\n    print(f\"\\nFound {len(spec_matches)} sources with SDSS spectra\")\n    spec_df.head()\nelse:\n    print(\"\\nNo spectroscopic matches found\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 3. Parse FITS spectra \u2192 numpy arrays\n\nGoal: build arrays `wavelength`, `flux`, optional `ivar`, and labels.\nFor this exercise, you will **define your own labels** for a binary and a multiclass task.\nSuggestions:\n- Binary: strong emission vs weak/no emission (use heuristic on H\u03b1 region)\n- Multiclass: 3\u20134 bins by spectral features or by a metadata column if available\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# TODO: Implement FITS parsing and heuristic labeling\n# - Walk through ./spectra/*.fits\n# - Extract wavelength, flux (and ivar if present)\n# - Build small arrays for train/val/test splits\n# - Define labels for binary and multiclass tasks\n# - Save to npz under ./intermediate/\n#\n# Pseudocode:\n# files = sorted(glob(\"./spectra/*.fits\"))\n# for fp in files:\n#     with fits.open(fp) as hdul:\n#         flux = hdul[1].data[\"flux\"] or similar\n#         loglam = hdul[1].data[\"loglam\"]  # SDSS often stores log10(lambda)\n#         wave = 10**loglam\n#         ivar = hdul[1].data.get(\"ivar\", None)\n#         ... your processing ...\n# Save: np.savez(\"./intermediate/spectra_train.npz\", wavelength=..., flux=..., ivar=..., label_binary=..., label_multi=...)\npass\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 4. Build a Transformer Encoder for spectra (skeleton)\n\nUse a learnable positional embedding, mask invalid/padded bins, and produce a pooled embedding for classification.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# TODO: Implement SpectraTransformer (encoder-only) and heads for binary/multiclass\n# class SpectraTransformer(nn.Module): ...\n# class BinaryHead(nn.Module): ...\n# class MultiHead(nn.Module): ...\npass\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 5. Training & Evaluation\n\n- Train binary classifier. Report ROC AUC, PR AUC, accuracy, F1.\n- Tune a decision threshold on the validation set using the PR curve.\n- Train multiclass classifier. Report macro-F1 and plot confusion matrix.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# TODO: Dataloaders, training loops, evaluation metrics, and plots\n# Tips:\n# - Use BCEWithLogitsLoss for binary, CrossEntropyLoss for multiclass\n# - Consider class weights if imbalance is severe\n# - Plot ROC, PR, confusion matrix\npass\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n### 6. Optional: Calibration & Uncertainty (bonus)\n\n- Implement temperature scaling on the validation logits to reduce overconfidence.\n- Try MC dropout at test time to estimate predictive variance.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}